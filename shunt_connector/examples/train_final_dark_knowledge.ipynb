{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "d8b274d99e8fb8d9facd229017fb192c20e27208913b8ae525f29c1e2086d313"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import shunt_connector\n",
    "\n",
    "# PARAMS\n",
    "temperature = 3.0\n",
    "distillation_strength = 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "config_path = Path(\"config\", \"dark_knowledge.cfg\")\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_path)\n",
    "\n",
    "connector = shunt_connector.ShuntConnector(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Create dataset\n",
      "CIFAR10 was loaded successfully!\n",
      "\n",
      "Create original model\n",
      "MobileNetV3Small created successfully!\n",
      "{'conv2d': 5137856.0, 'depthwise_conv2d': 1450240.0, 'total': 6588096.0}\n",
      "\n",
      "Test original model\n",
      "10/10 [==============================] - 7s 14ms/step - loss: 2.4034 - categorical_crossentropy: 2.3026 - categorical_accuracy: 0.0283\n",
      "loss: 2.40339\n",
      "categorical_crossentropy: 2.30259\n",
      "categorical_accuracy: 0.10000\n",
      "\n",
      "Create shunt model\n",
      "Used dilation rates: [1, 1]\n",
      "\n",
      "Test shunt model\n",
      "10/10 [==============================] - 4s 14ms/step - loss: 0.1185\n",
      "Loss: 0.11851\n",
      "\n",
      "Create final model\n"
     ]
    }
   ],
   "source": [
    "connector.create_dataset()\n",
    "connector.create_original_model()\n",
    "connector.test_original_model()\n",
    "connector.create_shunt_model()\n",
    "connector.test_shunt_model()\n",
    "connector.create_final_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'shunt_connector.utils' has no attribute 'create_distillation_trainings_model'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2923dd565824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mconnector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivate_distribution_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     model_final_dist = shunt_connector.utils.create_distillation_trainings_model.create_classification_distillation_model(connector.final_model,\n\u001b[0m\u001b[1;32m     30\u001b[0m                                                                                                                           \u001b[0mconnector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moriginal_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                                                                                           \u001b[0madd_dark_knowledge\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'shunt_connector.utils' has no attribute 'create_distillation_trainings_model'"
     ]
    }
   ],
   "source": [
    "from shunt_connector.utils import create_distillation_trainings_model\n",
    "from shunt_connector.utils import custom_callbacks\n",
    "from shunt_connector.utils import custom_loss_metric\n",
    "\n",
    "\n",
    "# learning rate strategy\n",
    "if connector.train_final_params['learning_policy'] == 'two_cycles':\n",
    "    callback_learning_rate = custom_callbacks.LearningRateSchedulerCallback(epochs_first_cycle=connector.train_final_params['epochs_first_cycle'],\n",
    "                                                            learning_rate_second_cycle=connector.train_final_params['learning_rate_second_cycle'])\n",
    "elif connector.train_final_params['learning_policy'] == 'plateau':\n",
    "    callback_learning_rate = keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
    "                                                factor=connector.train_final_params['factor'],\n",
    "                                                patience=connector.train_final_params['patience'],\n",
    "                                                verbose=1,\n",
    "                                                mode='auto',\n",
    "                                                min_lr=1e-8)\n",
    "elif connector.train_final_params['learning_policy'] == 'poly':\n",
    "    callback_learning_rate = custom_callbacks.PolyLearningRateCallback(connector.train_final_params['power'],\n",
    "                                                        connector.train_final_params['max_epochs'],\n",
    "                                                        verbose=1)\n",
    "\n",
    "# freezing strategy\n",
    "if connector.train_final_params['freezing'] == 'nothing':\n",
    "    pass\n",
    "elif connector.train_final_params['freezing'] == 'freeze_before_shunt':\n",
    "    for i, layer in enumerate(connector.final_model.layers):\n",
    "        if i < connector.shunt_params['locations'][0]:  # TODO: TEST THIS!!\n",
    "            layer.trainable = False\n",
    "\n",
    "loss_dict = {}\n",
    "metric_dict = {}\n",
    "\n",
    "with connector.activate_distribution_scope():\n",
    "    model_final_dist = create_distillation_trainings_model.create_classification_distillation_model(connector.final_model,\n",
    "                                                                                                    connector.original_model,\n",
    "                                                                                                    add_dark_knowledge=True,\n",
    "                                                                                                    temperature=temperature)\n",
    "    \n",
    "    loss_dict = {'Student': 'categorical_crossentropy'}\n",
    "    metric_dict = {'Student': ['accuracy']}\n",
    "    callback_checkpoint = custom_callbacks.SaveNestedModelCallback('val_Student_accuracy', str(Path(connector.folder_name_logging, \"final_model_weights.h5\")), 'Student')\n",
    "    for output in model_final_dist.output:\n",
    "        output_name = output.name.split('/')[0] # cut off unimportant part\n",
    "        if 'd_k' in output_name:\n",
    "            loss_dict[output_name] = custom_loss_metric.create_negative_sum_loss(distillation_strength)\n",
    "\n",
    "callbacks = [callback_checkpoint, callback_learning_rate]\n",
    "\n",
    "with connector.distribute_strategy.scope():\n",
    "    model_final_dist.compile(loss=loss_dict,\n",
    "                        optimizer=keras.optimizers.SGD(lr=connector.train_final_params['base_learning_rate'],momentum=0.9, decay=0.0, nesterov=False),\n",
    "                        metrics=metric_dict)\n",
    "\n",
    "history_final = model_final_dist.fit(connector.dataset_train.batch(connector.train_final_params['batch_size']),\n",
    "                                epochs=connector.train_final_params['max_epochs'],\n",
    "                                steps_per_epoch=connector.dataset_props['len_train_data']//connector.train_final_params['batch_size'],\n",
    "                                validation_data=connector.dataset_val.batch(connector.train_final_params['batch_size']),\n",
    "                                validation_steps=connector.dataset_props['len_val_data']//connector.train_final_params['batch_size'],\n",
    "                                verbose=1, \n",
    "                                callbacks=callbacks)\n",
    "\n",
    "connector.final_model.load_weights(str(Path(connector.folder_name_logging, \"final_model_weights.h5\")))\n",
    "\n",
    "keras.models.save_model(connector.final_model, Path(connector.folder_name_logging, \"final_model.h5\"))\n",
    "logging.info('')\n",
    "logging.info('Final model saved to {}'.format(connector.folder_name_logging))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Test final model\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 2.4051 - categorical_crossentropy: 2.2976 - categorical_accuracy: 0.1000\n",
      "loss: 2.40509\n",
      "categorical_crossentropy: 2.29756\n",
      "categorical_accuracy: 0.10000\n"
     ]
    }
   ],
   "source": [
    "connector.test_final_model()\n",
    "connector.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}